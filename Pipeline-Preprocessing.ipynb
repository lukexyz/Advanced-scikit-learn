{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Pipelines \n",
    "\n",
    "This notebook shows how to implement pipelines to simplify the model creation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load data\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM score WITHOUT pipeline: 0.9844444444444445\n"
     ]
    }
   ],
   "source": [
    "# without pipelines\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "svm = SVC().fit(X_train_scaled, y_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "score = svm.score(X_test_scaled, y_test)\n",
    "print('SVM score WITHOUT pipeline: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM score WITH pipeline: 0.9844444444444445\n"
     ]
    }
   ],
   "source": [
    "# with pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# verbose constructor\n",
    "pipe = Pipeline([(\"my_scaler\", StandardScaler()), (\"my_svm\", SVC())])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "score_p = pipe.score(X_test, y_test)\n",
    "print('SVM score WITH pipeline: {}'.format(score_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly the same as before, as desired.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longer Pipelines\n",
    "\n",
    "Pipelines are not limited to two steps. The only requirement is that all but the last step needs to have a .transform method.\n",
    "\n",
    "Here is an example of a longer pipeline and its' transformations:\n",
    "\n",
    "1. The pipeline first drops features with little variance\n",
    "2. Feature scaling\n",
    "3. Statistical feature selection\n",
    "4. Training the SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM score: 0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectFdr, VarianceThreshold\n",
    "\n",
    "# transformations ----------\\/-------------------\\/--------------\\/------------\n",
    "pipe = make_pipeline(VarianceThreshold(), StandardScaler(), SelectFdr(), SVC())\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "score_l = pipe.score(X_test, y_test)\n",
    "print('SVM score: {}'.format(score_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Pipelines\n",
    "\n",
    "* Reduce to 10 dimensions\n",
    "* Find 10 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 4, ..., 5, 5, 7], dtype=int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "cluster_pipe = make_pipeline(PCA(n_components=10), KMeans(n_clusters=10))\n",
    "cluster_pipe.fit(X_train)\n",
    "cluster_pipe.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, n_components=10, whiten=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_pipe.named_steps['pca'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_pipe.named_steps['pca'].components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_pipe.named_steps['kmeans']\n",
    "cluster_pipe.named_steps['kmeans'].cluster_centers_.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
